{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/s00hyunkim/quora-insincere-questions/blob/main/3_text_classification_decision_tree_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXovkTfPj2BK"
      },
      "source": [
        "# Model 1: Text Classification with `sklearn`\n",
        "\n",
        "Our goal is to build a ML model that uses the features to predict the label:\n",
        "- **Feature:** A bag of words (questions from Quora users; `question_text` in the `train.csv` and `test.csv` datasets)\n",
        "- **Label (Binary):** Insincere (TRUE or FALSE; `target` in the `train.csv` dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs40PdQuj2BM"
      },
      "source": [
        "## Step 1: Import libraries\n",
        "\n",
        "Ensure that all the required libraries have been installed by running `pip install <LIBRARY>` in the terminal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IKxeeTQWj2BM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "89892778-5280-48c1-9ade-97b8d7e4adb0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "        <script type=\"text/javascript\">\n",
              "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
              "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
              "        if (typeof require !== 'undefined') {\n",
              "        require.undef(\"plotly\");\n",
              "        requirejs.config({\n",
              "            paths: {\n",
              "                'plotly': ['https://cdn.plot.ly/plotly-2.8.3.min']\n",
              "            }\n",
              "        });\n",
              "        require(['plotly'], function(Plotly) {\n",
              "            window._Plotly = Plotly;\n",
              "        });\n",
              "        }\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "\n",
        "from plotly.offline import init_notebook_mode,iplot\n",
        "init_notebook_mode(connected=True)\n",
        "import plotly.graph_objs as go\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from wordcloud import WordCloud\n",
        "import string\n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split,GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix,f1_score,roc_curve,make_scorer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.manifold import TSNE\n",
        "import os\n",
        "\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "\n",
        "stemmer=SnowballStemmer('english')\n",
        "seed=5\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVwN8YAUj2BN"
      },
      "source": [
        "## Step 2: Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92uZORQXj2BN"
      },
      "outputs": [],
      "source": [
        "# loading train and test datasets\n",
        "\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "\n",
        "# printing the first 5 rows of train dataset\n",
        "train.head()\n",
        "\n",
        "# printing the first 5 rows of test dataset\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97JNiwznYdwo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ntpz1aRnj2BO"
      },
      "source": [
        "## Step 3: Perform Text Vectorization\n",
        "\n",
        "Text Vectorization is the process of converting text into numerical representation.\n",
        "\n",
        "For our use case, we are converting `question_text` to a matrix of TF-IDF (which measures the frequency of a word in a text against its overall frequency in the corpus) features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kAvt8g1xj2BO"
      },
      "outputs": [],
      "source": [
        "text_vectorizer = TfidfVectorizer(max_features = 2000)\n",
        "\n",
        "train_vector = text_vectorizer.fit_transform(train[\"question_text\"])\n",
        "test_vector = text_vectorizer.transform(test[\"question_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4nLTg-Sj2BO"
      },
      "source": [
        "## Step 4: Splitting X and Y into training and validation sets\n",
        "\n",
        "As Quora provided the train and test datasets separately, there is no need to split X and Y into training and testing sets. Instead, X and Y are split into training and validation sets.\n",
        "\n",
        "The `stratify` argument is used for Y to be split into training and validation sets as they are in the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GN4Izqufj2BO"
      },
      "outputs": [],
      "source": [
        "X_train,X_val,y_train,y_val = train_test_split(\n",
        "    train_vector,\n",
        "    train[\"target\"],\n",
        "    test_size=0.2,\n",
        "    stratify=train[\"target\"],\n",
        "    random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMwBcPtdj2BO"
      },
      "source": [
        "## Step 5: Choose classifiers\n",
        "\n",
        "The three chosen classifers are the following models:\n",
        "\n",
        "    - Decision Tree Classifier "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Es57Hy_ej2BP"
      },
      "outputs": [],
      "source": [
        "# setting up the DecisionTreeClassifier model\n",
        "dtc_model = DecisionTreeClassifier(random_state=seed, max_depth=30)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4RBR6NAj2BP"
      },
      "source": [
        "## Step 6: Train the chosen classifiers and calculate metrics\n",
        "\n",
        "The metrics that are used to analyze the performance are:\n",
        "\n",
        "    - F-1 Score\n",
        "    - ROC AUC Score\n",
        "\n",
        "Along with these two scores, the confusion matrix is displayed with a _heatmap_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sftWohJbj2BP"
      },
      "outputs": [],
      "source": [
        "# scaling X\n",
        "scaler_X = StandardScaler(with_mean=False)\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "\n",
        "# creating a method that train the model, predict using the model, and calculate metrics\n",
        "def model_and_predict(model, X_train_scaled, y_train, X_val_scaled, y_val):\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_val_scaled)\n",
        "\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    fpr, tpr, _ = roc_curve(y_val, y_pred)\n",
        "    auc = roc_auc_score(y_val, y_pred)\n",
        "    conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "    print(\"[Text Classification using %s]\"%(model))\n",
        "    print(\"   1) F1 score: %.2f\"%(f1))\n",
        "    print(\"   2) ROC AUC score: %.2f\"%(auc))\n",
        "    print(\"   3) ROC Curve\")\n",
        "    plt.plot(fpr, tpr, label='AUC Score = %.2f'%(auc))\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.legend(loc=4)\n",
        "    plt.show()\n",
        "    print(\"   4) Confusion Matrix\")\n",
        "    group_names = ['True Negative','False Positive','False Negative','True Positive']\n",
        "    group_counts = [\"{0:0.0f}\".format(value) for value in conf_matrix.flatten()]\n",
        "    group_percentages = [\"{0:.2%}\".format(value) for value in conf_matrix.flatten()/np.sum(conf_matrix)]\n",
        "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "    sns.heatmap(conf_matrix, annot=labels, fmt='')\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "  \n",
        "\n",
        "\n",
        "\n",
        "# calling method above for every model\n",
        "baseline_models = [dtc_model]\n",
        "for model in baseline_models:\n",
        "    model_and_predict(model, X_train_scaled, y_train, X_val_scaled, y_val)\n",
        "     \n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "787ae017fa22a3d9ce9bac8a0aea523ecd295336d18ae2230ac9ba7e19112084"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}