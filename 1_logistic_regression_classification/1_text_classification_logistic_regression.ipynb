{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBZ697MSdfGi"
      },
      "source": [
        "# Model 1: Text Classification with Logistic Regression using `sklearn`\n",
        "\n",
        "Our goal is to build a ML model that uses the features to predict the label:\n",
        "- **Feature:** A bag of words (questions from Quora users; `question_text` in the `train.csv` and `test.csv` datasets)\n",
        "- **Label (Binary):** Insincere (TRUE or FALSE; `target` in the `train.csv` dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbQTAsWxdfGs"
      },
      "source": [
        "## Step 1: Import libraries\n",
        "\n",
        "Ensure that all the required libraries have been installed by running `pip install <LIBRARY>` in the terminal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28mRFFHedfGx"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "%matplotlib inline\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score, f1_score\n",
        "from sklearn.model_selection import cross_val_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr6aFg5bdfG3"
      },
      "source": [
        "## Step 2: Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LXxI8HS4dfG7"
      },
      "outputs": [],
      "source": [
        "# loading train and test datasets\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "\n",
        "# printing the first 5 rows of train dataset\n",
        "train.head()\n",
        "\n",
        "# printing the first 5 rows of test dataset\n",
        "test.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-GUzBrkdfG9"
      },
      "source": [
        "## Step 3: Perform Text Vectorization\n",
        "\n",
        "Text Vectorization is the process of converting text into numerical representation.\n",
        "\n",
        "For our use case, we are converting `question_text` to a matrix of TF-IDF (which measures the frequency of a word in a text against its overall frequency in the corpus) features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWXHUKeSdfHA"
      },
      "outputs": [],
      "source": [
        "text_vectorizer = TfidfVectorizer(max_features=2000)\n",
        "\n",
        "train_vector = text_vectorizer.fit_transform(train[\"question_text\"])\n",
        "test_vector = text_vectorizer.transform(test[\"question_text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-glRO-HgdfHC"
      },
      "source": [
        "## Step 4: Splitting X and Y into training and validation sets\n",
        "\n",
        "As Quora provided the train and test datasets separately, there is no need to split X and Y into training and testing sets. Instead, X and Y are split into training and validation sets.\n",
        "\n",
        "The `stratify` argument is used for Y to be split into training and validation sets as they are in the original dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbs3oiihdfHE"
      },
      "outputs": [],
      "source": [
        "X_train,X_val,y_train,y_val = train_test_split(\n",
        "    train_vector,\n",
        "    train[\"target\"],\n",
        "    test_size=0.2,\n",
        "    stratify=train[\"target\"],\n",
        "    random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IM5Jea1AdfHG"
      },
      "source": [
        "## Step 5: Choose classifiers\n",
        "\n",
        "The three chosen classifers are the following models:\n",
        "\n",
        "    - Logistic Regression\n",
        "    - SVM with linear kernel\n",
        "    - Bernoulli"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tkaHyYd0dfHI"
      },
      "outputs": [],
      "source": [
        "# setting up the Logistic Regression model\n",
        "# log_model = LogisticRegression(solver='lbfgs', max_iter=3000)\n",
        "log_model = LogisticRegression(max_iter=3000)\n",
        "\n",
        "# setting up the SVM model with linear kernel\n",
        "# svm_model = SVC(kernel='rbf')\n",
        "\n",
        "# setting up the Bernoulli model\n",
        "# bernoulli_model = BernoulliNB()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 6: Use cross-validation to find the best-performing hyperparameters for the Logistic Regression model\n",
        "\n",
        "The hyperparameters that are to be found are:\n",
        "\n",
        "    - Penalty (L1 or L2)\n",
        "    - Regularization Strength ([0, 4])"
      ],
      "metadata": {
        "id": "0W7rkGfjiNcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling X\n",
        "scaler_X = StandardScaler(with_mean=False)\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "\n",
        "# creating a list of penalty values to be tested\n",
        "penalty = ['l1', 'l2']\n",
        "\n",
        "# creating a list of regularization strength values to be tested\n",
        "C = np.logspace(0, 4, 10)\n",
        "\n",
        "# combining the two lists into a dictionary\n",
        "hyperparameters = dict(C=C, penalty=penalty)\n",
        "\n",
        "# fitting log_model using GridSearchCV\n",
        "log_cv = GridSearchCV(log_model, hyperparameters, cv=5, verbose=0)\n",
        "best_log_model = log_cv.fit(X_train_scaled, y_train)\n",
        "\n",
        "# printing results\n",
        "print(\"[GridSearchCV Results]\")\n",
        "print(\"   1) Best penalty has been found to be \", best_log_model.best_estimator_.get_params()['penalty'])\n",
        "print(\"   2) Best regularization strength has been found to be \", best_log_model.best_estimator_.get_params()['C'])"
      ],
      "metadata": {
        "id": "wchVsG_8ixmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dc63QX5EdfHL"
      },
      "source": [
        "## Step 7: Train the chosen classifiers and calculate metrics\n",
        "\n",
        "The metrics that are used to analyze the performance are:\n",
        "\n",
        "    - F-1 Score\n",
        "    - ROC AUC Score\n",
        "\n",
        "Along with these two scores, the confusion matrix is displayed with a _heatmap_."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVFiHP5DdfHM"
      },
      "outputs": [],
      "source": [
        "# creating a method that train the model, predict using the model, and calculate metrics\n",
        "def model_and_predict(model, X_train_scaled, y_train, X_val_scaled, y_val):\n",
        "    # finding train/test indices to split data in train and test sets\n",
        "    kfold = KFold(n_splits=5, random_state=42, shuffle=True)\n",
        "\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_val_scaled)\n",
        "    y_pred_auc = model.predict_proba(X_val_scaled) # auc score uses predict_proba() under the hood, not predict()\n",
        "\n",
        "    f1 = f1_score(y_val, y_pred)\n",
        "    f1_train_cv = cross_val_score(model, X_train_scaled, y_train, scoring=\"f1\", cv=kfold)\n",
        "    mean_f1_train_cv = f1_train_cv.mean()\n",
        "    std_f1_train_cv = f1_train_cv.std()\n",
        "    f1_test_cv = cross_val_score(model, X_val_scaled, y_val, scoring=\"f1\", cv=kfold)\n",
        "    mean_f1_val_cv = f1_test_cv.mean()\n",
        "    std_f1_val_cv = f1_test_cv.std()\n",
        "    fpr, tpr, _ = roc_curve(y_val, y_pred_auc[:, 1])\n",
        "    auc = roc_auc_score(y_val, y_pred_auc[:, 1])\n",
        "    auc_train_cv = cross_val_score(model, X_train_scaled, y_train, scoring=\"roc_auc\", cv=kfold)\n",
        "    mean_auc_train_cv = auc_train_cv.mean()\n",
        "    std_auc_train_cv = auc_train_cv.std()\n",
        "    auc_val_cv = cross_val_score(model, X_val_scaled, y_val, scoring=\"roc_auc\", cv=kfold)\n",
        "    mean_auc_val_cv = auc_val_cv.mean()\n",
        "    std_auc_val_cv = auc_val_cv.std()\n",
        "    conf_matrix = confusion_matrix(y_val, y_pred)\n",
        "\n",
        "    print(\"[Text Classification using %s]\"%(model))\n",
        "    print(\"   1) F1 score: %.2f\"%(f1))\n",
        "    print(\"      - Mean F1 score for train set in cross validation: %.2f\"%(mean_f1_train_cv))\n",
        "    print(\"      - Standard deviation of F1 score for train set in cross validation: %.2f\"%(std_f1_train_cv))\n",
        "    print(\"      - Mean F1 score for test set in cross validation: %.2f\"%(mean_f1_val_cv))\n",
        "    print(\"      - Standard deviation of F1 score for test set in cross validation: %.2f\"%(std_f1_val_cv))\n",
        "    print(\"   2) ROC AUC score: %.2f\"%(auc))\n",
        "    print(\"      - Mean ROC AUC score for train set in cross validation: %.2f\"%(mean_auc_train_cv))\n",
        "    print(\"      - Standard deviation of ROC AUC score for train set in cross validation: %.2f\"%(std_auc_train_cv))\n",
        "    print(\"      - Mean ROC AUC score for test set in cross validation: %.2f\"%(mean_auc_val_cv))\n",
        "    print(\"      - Standard deviation of ROC AUC score for test set in cross validation: %.2f\"%(std_auc_val_cv))\n",
        "    print(\"   3) ROC Curve\")\n",
        "    plt.plot(fpr, tpr, label='AUC Score = %.2f'%(auc))\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.legend(loc=4)\n",
        "    plt.show()\n",
        "    # plt.savefig('C:/Users/Soohyun/Desktop/UW MGTE \\'23/YEAR 4/4B/MSCI 546/Term Project/quora-insincere-questions/1_baseline_classification/images/roc_curve_log_reg.png')\n",
        "    # plt.close()\n",
        "    print(\"   4) Confusion Matrix\")\n",
        "    group_names = ['True Negative','False Positive','False Negative','True Positive']\n",
        "    group_counts = [\"{0:0.0f}\".format(value) for value in conf_matrix.flatten()]\n",
        "    group_percentages = [\"{0:.2%}\".format(value) for value in conf_matrix.flatten()/np.sum(conf_matrix)]\n",
        "    labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)]\n",
        "    labels = np.asarray(labels).reshape(2,2)\n",
        "    sns.heatmap(conf_matrix, annot=labels, fmt='')\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "    # plt.savefig('C:/Users/Soohyun/Desktop/UW MGTE \\'23/YEAR 4/4B/MSCI 546/Term Project/quora-insincere-questions/1_baseline_classification/images/confusion_matrix_log_reg.png')\n",
        "    # plt.close()\n",
        "\n",
        "# calling method above for every model but commenting it out to reduce computational time\n",
        "# baseline_models = [log_model, svm_model, bernoulli_model]\n",
        "\n",
        "# calling method above for logistic regression model only\n",
        "baseline_models = [LogisticRegression(penalty='l2', max_iter=3000)]\n",
        "for model in baseline_models:\n",
        "    model_and_predict(model, X_train_scaled, y_train, X_val_scaled, y_val)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "787ae017fa22a3d9ce9bac8a0aea523ecd295336d18ae2230ac9ba7e19112084"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}