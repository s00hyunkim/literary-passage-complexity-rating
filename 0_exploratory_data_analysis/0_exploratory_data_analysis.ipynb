{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHrsZaex37jl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "\n",
        "# For numerical arrays\n",
        "import numpy as np \n",
        "\n",
        "# For visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install pyspellchecker\n",
        "# import all necessary libraries\n",
        "\n",
        "# For dataframes\n",
        "import pandas as pd \n",
        "\n",
        "# For numerical arrays\n",
        "import numpy as np \n",
        "\n",
        "# For stemming/Lemmatisation/POS tagging\n",
        "import spacy\n",
        "\n",
        "# For getting stopwords\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "# For K-Fold cross validation\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# For visualizations\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# For regular expressions\n",
        "import re\n",
        "\n",
        "# For handling string\n",
        "import string\n",
        "\n",
        "# For all torch-supported actions\n",
        "import torch\n",
        "\n",
        "# For spell-check\n",
        "# from spellchecker import SpellChecker\n",
        "\n",
        "# For performing mathematical operations\n",
        "import math\n",
        "\n",
        "# For dictionary related activites\n",
        "from collections import defaultdict\n",
        "\n",
        "# For counting actions (EDA)\n",
        "from collections import  Counter\n",
        "\n",
        "# For count vectorisation (EDA)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# For one-hot encoding\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# For DL model\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, LSTM\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "\n",
        "# For generating random integers\n",
        "from random import randint\n",
        "\n",
        "#For making wordclouds\n",
        "from wordcloud import WordCloud \n",
        "\n",
        "# For TF-IDF vectorisation\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# For padding\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# For tokenization\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# For plotting\n",
        "import seaborn as sns\n",
        "\n",
        "print(\"Necessary libraries imported\")\n",
        "\n",
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n"
      ],
      "metadata": {
        "id": "Tk7a2PjtiHjx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "link = 'https://drive.google.com/file/d/1d-RwlndEiOUN8qf9UyTrRcSiH7Y5_J4K/view?usp=sharing'\n",
        "\n",
        "# to get the id part of the file\n",
        "id = link.split(\"/\")[-2]\n",
        "\n",
        "downloaded = drive.CreateFile({'id':id})\n",
        "downloaded.GetContentFile('train.csv')\n",
        "df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "UvBHODxHRgpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(10)"
      ],
      "metadata": {
        "id": "3XrUkeYUSMQb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "LzRCt_3jkmJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CZe2T2E1imR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset Description"
      ],
      "metadata": {
        "id": "xhE5JdEvdsfX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total rows in dataset: ', len(df), 'Rows\\n')\n",
        "print('Dataset Columns: ')\n",
        "print(df.columns)\n",
        "print('\\n Null Statistics:')\n",
        "print(df.isnull().sum())\n",
        "print('\\n Frequency of Insincere Questions: ')\n",
        "print(df.groupby(\"target\").describe().loc[:,[('question_text',  'count'),('question_text', 'unique')]])\n",
        "print('\\n Pie Plot of Targets')\n",
        "df.target.value_counts().plot(title='Target categories', kind='pie')"
      ],
      "metadata": {
        "id": "yDPP26g_XM_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Word length vs. target"
      ],
      "metadata": {
        "id": "MXq-Rap0dwhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['total_words']=df.question_text.apply(lambda x: len(x.split()))\n",
        "print(\"Boxplot for Target vs total words\")\n",
        "plt.plot(figsize=(8,15)) \n",
        "plt.title('Target versus total words')\n",
        "\n",
        "sns.boxplot(data=df,\n",
        "    x=\"target\", y=\"total_words\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fCbV75gsixKp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}